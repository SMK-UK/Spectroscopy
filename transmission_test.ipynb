{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectroscopic Data Analysis\n",
    "        Sean Keenan, PhD Physics\n",
    "        Quantum Memories Group, Heriot-Watt University, Edinburgh\n",
    "        2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as mp\n",
    "import scipy.interpolate as si\n",
    "import scipy.signal as ss\n",
    "import scipy.ndimage as nd\n",
    "import spec_funcs as sf\n",
    "from scipy.fftpack import rfft, irfft, fftfreq\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set-up script\n",
    "        Select input folder and polarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to gui at later date\n",
    "# polarisations as written in file names\n",
    "polarisations = [\"143\",\"180\"]\n",
    "\n",
    "# folder containing all the requisite subfolders and data - refrences included\n",
    "path = \"C:\\\\Users\\\\keena\\\\Desktop\\\\Analyse\"\n",
    "\n",
    "\n",
    "# choose to focus on a particular wavelength range\n",
    "zoom = False\n",
    "lower = 580\n",
    "upper = 650\n",
    "\n",
    "# mark energies / wavelengths of interest\n",
    "view = False\n",
    "woi = [594.24, 603.23, 604.24]\n",
    "\n",
    "# value to shift each OD\n",
    "shifter = 0\n",
    "\n",
    "# save images \n",
    "save_fig = False\n",
    "\n",
    "# reference names\n",
    "refs = \"ref\", \"reference\"\n",
    "\n",
    "# file extension types\n",
    "exts = (\".csv\", \".txt\", \".CSV\")\n",
    "exceptions = (\"notes\", \"setup\")\n",
    "\n",
    "# initialise lists\n",
    "OD = []\n",
    "wave_sets = []\n",
    "I_sets = []\n",
    "bg_wavelengths = []\n",
    "bg_Is = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Raw Spectroscopy Data\n",
    "        Load raw data from csv file (delimiter is not a problem) and sort into groups - polarisations -> reference / spectrum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list, file_list = sf.dir_interogate(path, exts, exceptions)\n",
    "path_names = sf.read_files(folder_list, file_list)\n",
    "include, exclude = sf.search_paths(path_names, refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holder removes first folder from lists so only actual data is used\n",
    "holder = 0\n",
    "# walk through directory and extract all relevant files\n",
    "for root, dirs, files in os.walk(path):\n",
    "    if holder == 1:\n",
    "        folder_list.append(root)\n",
    "        temp = []\n",
    "        for file in files:\n",
    "            if(file.endswith(exts)):\n",
    "                # ignore collection data notes\n",
    "                if \"notes\" in file or \"setup\" in file:\n",
    "                    continue\n",
    "                else:\n",
    "                    temp.append(file)\n",
    "        file_list.append(temp)\n",
    "    else:\n",
    "        holder = 1\n",
    "\n",
    "'''\n",
    "filter through files and seperate transmission data into groups:\n",
    "polarisation > references > separators eg. temperature > transmission sets\n",
    "'''\n",
    "for polarisation in polarisations:\n",
    "    wavelengths = []\n",
    "    Is = []\n",
    "    for index, folder in enumerate(folder_list):\n",
    "        for file in file_list[index]:\n",
    "            dataset = os.path.join(folder, file)\n",
    "            if polarisation in dataset:\n",
    "                # check for reference data\n",
    "                # add flag if no reference!\n",
    "                if any(string in refs for string in dataset):\n",
    "                    bg_temp_wave = []\n",
    "                    bg_temp_I = []\n",
    "                    with open(dataset, 'r', newline='') as raw_file:\n",
    "                        for row in raw_file:\n",
    "                            if sf.check_str(row) == True:\n",
    "                                temp = re.split('\\t|,|;', row)\n",
    "                                bg_temp_wave.append(float(temp[0]))\n",
    "                                bg_temp_I.append(float(temp[1]))\n",
    "                        raw_file.close()\n",
    "                    bg_wavelengths.append(bg_temp_wave)\n",
    "                    bg_Is.append(bg_temp_I)\n",
    "                else:\n",
    "                    temp_wave = []\n",
    "                    temp_I =[]\n",
    "                    with open(dataset, 'r', newline='') as raw_file:\n",
    "                        for row in raw_file:\n",
    "                            if sf.check_str(row) == True:\n",
    "                                temp = re.split('\\t|,|;', row)\n",
    "                                temp_wave.append(float(temp[0]))\n",
    "                                temp_I.append(float(temp[1]))\n",
    "                        raw_file.close()\n",
    "                    wavelengths.append(temp_wave)\n",
    "                    Is.append(temp_I)\n",
    "    wave_sets.append(wavelengths)\n",
    "    I_sets.append(Is)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Calculate OD\n",
    "        Generate interplolated background data to match raw absorption data length and then calculate Optical Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Check lengths of arrays and interpolate reference data for each file - avoids issue of wavelength array length mismatch\n",
    "\n",
    "'''\n",
    "# cycle through polarisations\n",
    "for idx_1 in range(len(polarisations)):\n",
    "    temp_I_0 = []\n",
    "    temp_OD = []\n",
    "    I_temp = []\n",
    "    # generate spline co-effs\n",
    "    spline_coeffs = si.splrep(bg_wavelengths[idx_1], bg_Is[idx_1])\n",
    "    # calculate referenece for each wavelength subset\n",
    "    for idx_2, wavelength in enumerate(wave_sets[idx_1]):\n",
    "        spline_temp = (si.splev(wavelength, spline_coeffs))\n",
    "        I_temp = I_sets[idx_1][idx_2]\n",
    "        # scale data to remove negative values\n",
    "        if np.nanmin(spline_temp) < 0 or np.nanmin(I_temp) < 0:\n",
    "            if np.nanmin(spline_temp) < np.nanmin(I_temp):\n",
    "                adjust = np.nanmin(spline_temp)\n",
    "            elif np.nanmin(I_temp) < np.nanmin(spline_temp):\n",
    "                adjust = np.nanmin(I_temp)\n",
    "            temp_I_0.append(spline_temp - adjust)\n",
    "            I_temp -= adjust\n",
    "        else:\n",
    "            temp_I_0.append(spline_temp)\n",
    "        temp_OD.append(np.log(temp_I_0[idx_2]/I_temp))\n",
    "    I_0.append(temp_I_0)\n",
    "    OD.append(temp_OD)\n",
    "\n",
    "    # zoom function for wavelength range\n",
    "if zoom == True:\n",
    "    for index, waves in enumerate(wave_sets):\n",
    "        start = []\n",
    "        stop = []\n",
    "        for wave in waves:\n",
    "            for idx, value in enumerate(wave):\n",
    "                if value <= lower:\n",
    "                    temp_start = idx\n",
    "                if value <= upper:\n",
    "                    temp_stop = idx\n",
    "            start.append(temp_start)\n",
    "            stop.append(temp_stop)\n",
    "        starts.append(start)\n",
    "        stops.append(stop)\n",
    "elif zoom != True:\n",
    "    for index, waves in enumerate(wave_sets):\n",
    "        start = []\n",
    "        stop = []\n",
    "        for wave in waves:\n",
    "            start.append(0)\n",
    "            stop.append(-1)\n",
    "        starts.append(start)\n",
    "        stops.append(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print Raw Output\n",
    "        Plot individual spectroscopy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zoom == False:\n",
    "    string_format = path + '\\\\' + str(round(min(bg_wavelengths[0]))) + '_' + str(round(max(bg_wavelengths[0]))) + '_'\n",
    "else:\n",
    "    string_format = path + '\\\\' + str(lower) + '_' + str(upper) + '_'\n",
    "\n",
    "# create separate plots for each polarisation\n",
    "for idx_1, polarisation in enumerate(polarisations):\n",
    "    \n",
    "    fig_1, ax_1 = mp.subplots(figsize=(8, 5))\n",
    "    ax_1.set_title(str('Half-Wave Plate: ' + str(polarisation)))\n",
    "    ax_1.set(xlabel='Wavelength (nm)', ylabel='OD Normalised')\n",
    "    sec_ax = ax_1.secondary_xaxis('top', functions= (lambda x: 1e7 / x, lambda x: 1e7 / x))\n",
    "    sec_ax.set_xlabel('Wavenumber (cm$^{-1}$)')\n",
    "    ax_1.grid(True)\n",
    "    ax_1.grid(True, color='silver', linewidth=0.5)\n",
    "    if view == True:\n",
    "        for value in woi:\n",
    "            ax_1.axvline(x=value, linestyle='--')\n",
    "    \n",
    "    #shift each spectrum by a defined value\n",
    "    shift = 0\n",
    "    for idx_2, wave in enumerate(wave_sets[idx_1]):\n",
    "        lbl = os.path.split(folder_list[idx_2])\n",
    "        data = OD[idx_1][idx_2] - np.amin(OD[idx_1][idx_2]) + shift\n",
    "        ax_1.plot(wave[starts[idx_1][idx_2]:stops[idx_1][idx_2]], data[starts[idx_1][idx_2]:stops[idx_1][idx_2]], color=None, marker=None, linestyle='-', alpha=1, label=lbl[1])\n",
    "        shift += shifter  \n",
    "    \n",
    "    ax_1.legend(loc='upper left', fontsize=8)\n",
    "\n",
    "    if save_fig == True:\n",
    "        fig_1.savefig(fname=string_format + str(polarisation) + '.jpg', dpi='figure', format='jpg', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define ROI and fit to data\n",
    "        Determine feature profile - Gaussian / Lorentzian and return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi bounds (wavelength)\n",
    "roi_lower = 590\n",
    "roi_upper = 610\n",
    "\n",
    "# select to smooth data\n",
    "smooth = True\n",
    "sigma = 0.6\n",
    "\n",
    "# modifiers for peak finding (prominence, distance between peaks)\n",
    "prom_tol = 0.1\n",
    "dist = 10\n",
    "\n",
    "# array to identify indexes for roi\n",
    "roi_waves = []\n",
    "roi_ODs = []\n",
    "peaks = []\n",
    "smoothed = []\n",
    "smoothed_peaks = []\n",
    "for index, waves in enumerate(wave_sets):\n",
    "    roi_wave_temp = []\n",
    "    roi_OD_temp = []\n",
    "    temp_peaks = []\n",
    "    for index_2, wave in enumerate(waves):\n",
    "        for idx, value in enumerate(wave):\n",
    "            if value <= roi_lower:\n",
    "                temp_start = idx\n",
    "            if value <= roi_upper:\n",
    "                temp_stop = idx\n",
    "        roi_wave_temp.append(np.array(wave[temp_start:temp_stop]))\n",
    "        roi_OD_temp.append(OD[index][index_2][temp_start:temp_stop])\n",
    "        peak, _ = ss.find_peaks(roi_OD_temp[index_2], distance=dist, prominence=np.amax(roi_OD_temp[index_2]) * prom_tol)\n",
    "        temp_peaks.append(peak)\n",
    "        if smooth == True:\n",
    "            smoothed_temp = []\n",
    "            smoothed_peaks_temp = []\n",
    "            smoothed_temp.append(nd.gaussian_filter(roi_OD_temp[index_2], sigma))\n",
    "            smoothed_peaks_temp.append(ss.find_peaks(smoothed_temp[index_2], distance=dist, prominence=np.amax(smoothed_temp[index_2]) * prom_tol))\n",
    "    roi_waves.append(roi_wave_temp)\n",
    "    roi_ODs.append(roi_OD_temp)\n",
    "    peaks.append(temp_peaks)\n",
    "    smoothed.append(smoothed_temp)\n",
    "    smoothed_peaks.append(smoothed_peaks_temp)\n",
    "\n",
    "if smooth == True:\n",
    "    gauss_ODs = [nd.gaussian_filter(x, sigma) for x in roi_ODs]\n",
    "\n",
    "for idx_1, polarisation in enumerate(polarisations):\n",
    "\n",
    "    fig_2, ax_2 = mp.subplots(figsize=(8, 5))\n",
    "    ax_2.set_title(str('Half-Wave Plate: ' + str(polarisation)))\n",
    "    ax_2.set(xlabel='Wavelength (nm)', ylabel='OD Normalised')\n",
    "    sec_ax = ax_2.secondary_xaxis('top', functions= (lambda x: 1e7 / x, lambda x: 1e7 / x))\n",
    "    sec_ax.set_xlabel('Wavenumber (cm$^{-1}$)')\n",
    "    ax_2.grid(True)\n",
    "    ax_2.grid(True, color='silver', linewidth=0.5)\n",
    "    \n",
    "    for idx_2, data in enumerate(roi_waves[idx_1]):\n",
    "        ax_2.plot(data, roi_ODs[idx_1][idx_2])\n",
    "        ax_2.plot(data[peaks[idx_1][idx_2]], roi_ODs[idx_1][idx_2][peaks[idx_1][idx_2]], 'bx')\n",
    "        if smooth == True:\n",
    "            ax_2.plot(data, smoothed[idx_1][idx_2], '--r')\n",
    "        print('peak locations for Half-Wave Plate: ' + str(polarisation), peaks[idx_1][idx_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.diff(roi_ODs[4][0], n=1)\n",
    "diff_2 = np.diff(roi_ODs[4][0], n=2)\n",
    "diff_3 = np.diff(roi_ODs[4][0], n=3)\n",
    "\n",
    "mp.plot(diff)\n",
    "#mp.plot(diff_2)\n",
    "#mp.plot(diff_3)\n",
    "mp.plot(roi_ODs[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =np.linspace(-100, 100, 10000)\n",
    "amp_g = 40\n",
    "amp_l = 20\n",
    "y_0 = 0\n",
    "x_0g = 1\n",
    "x_0l = -1\n",
    "sigma = 15\n",
    "gamma = 40\n",
    "eta = 0.8\n",
    "\n",
    "gauss = sf.gaussian(x, amp_g, y_0, x_0g, sigma)\n",
    "lorentz = sf.lorentzian(x, amp_l, y_0, x_0l, gamma)\n",
    "noise = np.random.normal(size=np.size(gauss))\n",
    "\n",
    "voigt = sf.pseudo_voigt(x, y_0, amp_g, x_0g, sigma, amp_l, x_0l, gamma, eta) + noise\n",
    "\n",
    "mp.plot(x, gauss, 'r', label='gauss')\n",
    "mp.plot(x, lorentz, 'b', label='lorentz')\n",
    "mp.plot(x, voigt, 'orange', alpha=0.5, label='voigt')\n",
    "mp.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_g = sf.fitgauss(x, voigt)\n",
    "fit_l = sf.fitlorentz(x, voigt)\n",
    "fit_v = sf.fitgls(x, voigt)\n",
    "\n",
    "mp.plot(x, sf.lorentzian(x, *fit_l[0]), '--b', label='lorentz fit')\n",
    "mp.plot(x, sf.gaussian(x, *fit_g[0]), '--g', label='gauss fit')\n",
    "mp.plot(x, sf.pseudo_voigt(x, *fit_v[0]), '--r', label='voigt fit')\n",
    "mp.plot(x, voigt, color='orange', alpha=0.5, label='noisey voigt')\n",
    "mp.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d49c37c633d50b07b8251b4bba5a2f2b8c90a23d15a2181842cc17bf3d24abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
